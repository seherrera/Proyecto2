---
title: "Proyecto 2"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Proyecto 2
## Sebastian Herrera y Cristobal Paredes
## Importar Librerias
```{r cargar librerias}
library(tidyverse)
library(cluster)
library(factoextra)
library(janitor)
```
## Sample Datos
realizaremos un sample porque la cantidad de datos es muy grande y este computador no puede procesarlos, utilizaremos 10000 porque es un valor alto y nos permitira trabajar con un gran numero de datos
```{r sample}
setwd("C:/Users/sebah/Desktop/U/mineria de datos/proyecto n2")
load("C:/Users/sebah/Desktop/U/mineria de datos/proyecto n2/beats.RData")
beats <- beats %>% slice_sample(n=10000)
```


# Pre Procesamiento de los Datos
## Limpieza Datos:

- Primero verificar la existencia de valores NA o faltantes
```{r limpieza na}
# Para las observaciones que tengan datos faltantes, le asignamos el valor NA para eliminarlos en el siguiente paso
beats[beats == ""] <- NA

# Verificamos donde hay valores NAs
beats %>% 
  summarise_all(funs(sum(is.na(.))))

# De existir eliminamos todas las observaciones que presenten estos datos
beats_pre <- beats %>% 
  filter(!(is.na(track_name)|is.na(artist_name)|is.na(album_name)|is.na(duration_ms)))

# Corroboramos que no queden datos NA
beats_pre %>% 
  summarise_all(funs(sum(is.na(.))))

```

- Segundo filtrar y remover datos duplicados
```{r limpieza duplicados}
beats_pre <- beats_pre[!duplicated(beats_pre$track_id),]

```

- Tercero verificar la existencia de errores en los datos de las observaciones
```{r limpieza errores}



# Ahora corroboraremos si existen canciones que esten duplicadas
beats_pre %>% count(duplicated(beats_pre$track_name))

# Como existen canciones repetidas realizamos la consulta para obtener los valores distintos, pero este hecho obvia que hayan canciones con el mismo nombre pero de distinto autos  
beats_pre %>% distinct(track_name, .keep_all = TRUE, )

# Por lo que creamos una variables que almacene si existe duplicidad en la cacion y/o en el artista
beats_pre$duplicate <- duplicated(beats_pre[,c("track_name", "artist_name")])

# Generamos un sub beats frame que almacenara solo los valores que haya obtenido el valor TRUE a la consulta anterior y los ordenamos por track popularity
beats_dupli <- beats_pre %>% 
  filter(beats_pre$duplicate == TRUE) %>% 
  arrange("track_name", "danceability", desc(danceability))

# Seleciono las filas que sean distintas, borro todas las canciones que se repiten y me quedo con la mayor track popularity
beats_dupli <- beats_dupli %>% 
  distinct(track_name, artist_name, .keep_all = TRUE)

# Elimino de mi beats pre procesada los datos que dieron positivo a la duplicidad, para que al momento de re insertar los datos sobrevivieron a la limpieza de duplicidad no se genere la duplicidad que se estaba evitando
beats_pre <- beats_pre[!(beats_pre$duplicate == TRUE),]

# Junto la beats pre procesada con los datos que sobrevivieron a la limpieza de duplicidad
beats_pre <- rbind(beats_pre, beats_dupli)

# Elimino la columna que me indicaba duplicidad ya que no sera util mas adelante
beats_pre$duplicate <- NULL

```

el siguiente paso será escalar los datos

## Revisar Estructura Datos
```{r transformar tipo datos}
# transformacion de milisegundos a minutos
beats_pre <- beats_pre %>% mutate(duration_min = beats_pre$duration_ms/60000)

# Character
beats_char <- c("track_id", "track_name", "artist_name", "album_id","album_name", "explicit", "key_name")

# Double
beats_dou <- c("danceability", "energy", "key", "loudness", "mode", "speechiness", "acousticness", "instrumentalness", "liveness", "valence", "tempo", "duration_ms")

# Volvemos a borrar los datos que puedan haber quedado como NA con el cambio de tipo de variable
beats_pre <- beats_pre %>% 
  filter(!(is.na(key)|is.na(danceability)))
summary(beats_pre)
str(beats_pre)

```
## Separo Datos
```{r separar datos}
beatsnum <- beats_pre %>% 
  select(beats_dou)

beatschar <- beats_pre %>% 
  select(beats_char)

```

## Escalar Datos
```{r escalar datos}
beats_sca <- sapply(beatsnum, scale)
```

# Procesamiento de los Datos

## Clustering Jerarquico
 - Utilizaremos todas las variables para de esta manera crear una agrupación que reuna las canciones que son mas similares sin caer en tanta especifidad.

- Matriz de Distancias
```{r matriz distancia}
#Distancia Euclideana
d = dist(beats_sca, method = "euclidean")

#Distancia Manhattan
d1 = dist(beats_sca, method = "manhattan")

#Distancia Minkowski
d2 = dist(beats_sca, method = "minkowski")

hist(d, main = "Histograma Distancia Euclideana")
hist(d1, main = "Histograma Distancia Manhattan")
hist(d2, main = "Histograma Distancia Minkowski")
```

## Clustering Aglomerativo
 - Utilizando la funcion de R base hclust, aplicamos hierarchical clustering, a partir de la matriz de distancias d, y utilizamos el criterio complete linkage
realizamos este primer cluster para saparar las canciones en terminos generales para tener un ordenamiento de los datos y una mayor precision.
- Complete Model
```{r complete model}
#se fija una semilla para que no cambien los valores
set.seed(370)

model_complete <- hclust(d, method = "complete")

summary(model_complete)
```

- Ward Model
```{r ward model}
set.seed(370)

model_ward <- hclust(d, method = "ward.D")

summary(model_ward)
```

- Comparacion de los coeficientes de aglomeracion
```{r coef aglomeracion}
models <- c("single", "complete", "average", "ward")
names(models) <- c("single", "complete", "average", "ward")


```

 Generamos un dendrograma para visualizar la jerarquia

```{r grafico dendrograma}

library("ggdendro")

ggdendrogram(model_complete, rotate = TRUE, theme_dendro = TRUE) 

```

## Corte
```{r corte arbol}
# Determinamos un valor para h lo que nos entregara un valor distinto de k para cada h que escogamos
groups <- cutree(model_complete, h = 8)

# Se imprimen los tamaños de cada cluster
table(groups)

# Generamos una nueva columna para almacenar a que cluster pertenece cada observacion (tanto en beats_pre y beatsnum)
beats_pre$clust <- as.factor(groups)
beatsnum$clust <- as.factor(groups)

```

## Caracteristicas de los clusters encontrados
```{r caracteristicas clusters}
beatsnum$clust <- as.numeric(as.character(beatsnum$clust))

# Generamos una tabla que almacenara los valores promedios para cada uno de los clusters encontrados lo que nos permitira caracterizar a cada uno de ellos
infoclusters <- aggregate(beatsnum, by=list(cluster=beatsnum$clust), mean)

# Borramos la columna clust ya que se repite esa informacion en la tabla generada
infoclusters$clust <- NULL

# Transformamos el tiempo de la cancion a minutos
infoclusters <- infoclusters %>% mutate(duration_min = infoclusters$duration_ms/60000)

# Borramos la columna de la duracion en milisegundoss
infoclusters$duration_ms <- NULL

infoclusters
```
## creamos la playlist
```{r cancion inicial}
library(pracma)
#primera canción, seleccionaremos una cancion al azar simulando que es el usuario quien la esta escuchando
cancion1 <- sample(beatsnum$clust,1)
#ahora vemos las canciones que estan agrupadas con esta
beats_c <- beats_pre %>% 
  filter(beats_pre$clust == cancion1)

```

## creando playlist
 - Nos basaremos en la var energy esto porque queremos que la playlist acompañe al usuario con sus estados de animo. no queremos que aparezca una cancion muy activa si el esta buscando mas calma por ejemplo
```{r crear playlist}
desc(beats_c$energy)
#usaremos las canciones con mayor energia porque no queremos bajarle el animo a nadie
i<-0
sum<-0
playlist<-c("track_name","duration_min")
while(sum <180){
  playlist[i]<-beats_c$track_name[i]
  i<-i+1
  sum<- sum + beats_c$duration_min[i]
}
playlist
```